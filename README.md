# üïµÔ∏è‚Äç‚ôÇÔ∏è Detecci√≥n de Fraude en Transacciones con XGBoost

Este proyecto tiene como objetivo detectar transacciones fraudulentas en un conjunto de datos altamente desbalanceado, utilizando t√©cnicas de modelado con XGBoost, ajuste de umbral y evaluaci√≥n rigurosa.

---

## üìÇ Dataset

El dataset utilizado proviene de [Kaggle - Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud), que contiene:

- 284,807 transacciones
- 492 fraudes (‚âà 0.172%)
- Variables V1‚ÄìV28 generadas por PCA, m√°s `Amount`, `Time` y `Class` (target)

---

## ‚öôÔ∏è Proceso del proyecto

### 1. **An√°lisis exploratorio (EDA)**

- Se analizaron las distribuciones de `Amount` y `Time`
  - `Amount`: distribuci√≥n fuertemente sesgada a la derecha
  - `Time`: distribuci√≥n bimodal (actividad en dos franjas horarias)
- Se gener√≥ un **heatmap de correlaci√≥n**
  - La mayor√≠a de las variables PCA est√°n desacopladas
  - Algunas variables tienen leve correlaci√≥n con la clase (`V14`, `V10`, `V11`, `V17`‚Ä¶)

---

### 2. **Modelo base con XGBoost**

- Se utiliz√≥ `XGBClassifier` con:
  - `scale_pos_weight` ajustado como `negativos / positivos * 1.3`
  - `max_depth = 4`, `learning_rate = 0.1`, `n_estimators = 300`
  - Regularizaci√≥n: `reg_alpha = 0.5`, `reg_lambda = 1`
- M√©trica usada: `logloss`
- Se aplic√≥ **validaci√≥n cruzada estratificada (`StratifiedKFold`)**

---

### 3. **Ajuste del umbral de decisi√≥n**

- Se utiliz√≥ `cross_val_predict` con `predict_proba`
- Se ajust√≥ el **threshold a 0.35** para mejorar el recall sin da√±ar mucho la precisi√≥n

---

### 4. **Resultados Finales**

**Conjunto de test (20% hold-out):**

| M√©trica       | Valor     |
|---------------|-----------|
| F1-score clase 1 (fraude) | **0.8193** |
| Precision clase 1         | 0.8947     |
| Recall clase 1            | 0.7556     |
| Accuracy total            | 0.9995     |
| Falsos negativos          | 22 de 90   |
| Falsos positivos          | 8 de 56,656|

üìà **Matriz de confusi√≥n:**

![alt text](image.png)

üìà **Curva ROC:**

![alt text](image-1.png)
---

## üîç Importancia de Variables

Se utiliz√≥ `plot_importance` para identificar las variables m√°s influyentes:

- `V14`, `V10`, `V12`, `V19`, `V17`, `Amount` fueron las m√°s relevantes.
- Se evaluaron posibles eliminaciones de variables con `gain` bajo para simplificar el modelo, sin p√©rdida significativa de rendimiento.

---

## üî¨ T√©cnicas probadas pero descartadas

Se exploraron y **descartaron por empeorar resultados**:

- **SMOTE**, **RandomOverSampler** y **ADASYN**
  - Introduc√≠an ruido o sobreajuste
- **Undersampling** de clase 0
  - P√©rdida de informaci√≥n √∫til

---

## ‚úÖ Conclusi√≥n

El modelo final:
- Logra un excelente balance entre **recall** (detecci√≥n de fraude) y **precisi√≥n** (pocos falsos positivos)
- No necesita oversampling ni ingenier√≠a sint√©tica
- Es robusto, interpretable y eficiente


